<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Temel Kavramlar</title>
    <meta charset="utf-8" />
    <meta name="author" content="Hüseyin Taştan" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Temel Kavramlar
## (İktisatçılar İçin) Makine Öğrenmesi (TEK-ES 2020)
### Hüseyin Taştan
### Yıldız Teknik Üniversitesi

---

class: my-medium-font

&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 25px;
    padding: 1em 4em 1em 4em;
}
.my-large-font {
  font-size: 40px;
}
.my-small-font {
  font-size: 20px;
}
.my-medium-font {
  font-size: 30px;
}
&lt;/style&gt;


# Plan

- Makine Öğrenmesi Problemi 
- Öğrenme türleri: Gözetimli Öğrenme vs. Gözetimsiz Öğrenme
- Gözetimli Öğrenme: Regresyon problemleri 
- Gözetimli Öğrenme: Sınıflandırma problemleri 
- İndirgenemez Hata 
- Aşırı Uyum (overfitting)
- Eğitim ve Test verileri 
- Sapma-Varyans ilişkisi


---
# Makine Öğrenmesi
Makine Öğrenmesi (ML) bir girdi değişkenleri kümesinden hareketle çıktının kestirilmesi (tahmini) için (istatistiksel) modeller geliştirir.

**Genel çerçeve**: 


* `\(Y_i\)`: Çıktı değişkeni 
* `\(\mathbf{X}_i = \{X_{i1}, X_{i2},\ldots, X_{ip}\}\)`: kestirim değişkenleri ya da öznitelikler (features),

* Kestirim modeli: 
$$ Y_i = f(\mathbf{X}_i) + \epsilon_i, ~~~i=1,2,\ldots,n $$


Burada `\(f(\mathbf{X}_i)\)` bilinmeyen bir fonksiyon, `\(\epsilon\)` gözlenemeyen bir 
rassal hata terimidir.

---

# Gözetimli vs. Gözetimsiz Öğrenme 

- Gözetimli (supervised) öğrenme: Çıktı değişkeni `\(Y_i\)` gözlemleniyor. 

- `\(Y_i\)` sürekli değerler alıyorsa: **regresyon** problemi. Örneğin, evlerin özniteliklerinden hareketle değerinin tahmin edilmesi, borsa endeksinin yarınki kapanış değerinin öngörülmesi, vb.

- `\(Y_i\)` kategorik değişkense: **sınıflandırma** problemi. Örneğin, bir döviz kurunun yarınki hareketinin (aşağı ya da yukarı) öngörülmesi, bir kredi başvurusunun sınıflandırılması, vb. 

- Gözetimsiz öğrenme: Verilerde `\(Y_i\)` yok ya da gözlenemiyor. Amaç özniteliklerden hareketle gözlemlerin öbeklenmesi ya da öznitelik boyutunun küçültülmesi olabilir. Örnek: müşterilerin özelliklerinden hareketle piyasa segmentasyonu yapılması. 

---

# Regresyon Problemi Örnek: Gelir ve eğitim düzeyi

`$$Income = \underbrace{\beta_0 + \beta_1 Education}_{f(x)}+\epsilon$$`
.center[![](img/model1.PNG)]

---
# Örnek: Eğitim ve yaşın bir fonksiyonu olarak gelir düzeyi
$$ income = f(education, seniority) + \epsilon$$
.pull-left[
![:scale 100%](img/model2.PNG)
]


.pull-right[
- Kırmızı noktalar: gözlenen gelir düzeyleri
- Mavi yüzey: pratikte genelde bilinmeyen `\(f(\cdot)\)` fonksiyonu.

- Bu örnekte veriler simülasyonla elde edildiği için `\(f\)`  tam olarak biliniyor
]
---

# İndirgenebilir ve İndirgenemez Hata

* Bilinmeyen `\(f(X)\)` fonksiyonunun tahminine `\(\hat{f}(X)\)` diyelim. Bunun sonucunda elde edeceğimiz 
tahmin `\(\hat{Y} = \hat{f}(X)\)` 

* Bu `\(\hat{f}(X)\)`’nın tahmininde ortaya çıkan hataya **indirgenebilir hata** denir. Bu hatanın azaltılması ancak uygun kestirim fonksiyonunun bulunmasıyla mümkündür.

* `\(f(X)\)` pratikte bilinmez. Ancak bunu bilsek ve kestirimi buna göre oluştursak
`\(\hat{Y} = f(X)\)` bile bu kestirim hata içerecektir.  

* `\(\epsilon = Y - f(X)\)`: indirgenemez hata (irreducible error). Bu hata `\(X\)` değişkenleri kullanılarak 
tahmin edilemez. 

 
* Toplam değişkenlik iki parçaya ayrılabilir: 
`$$E[(Y-\hat{f}(X))^2|X=x] = ( f(x)-\hat{f}(x))^2 + Var(\epsilon)$$`

Burada `\(Var(\epsilon)\)` indirgenemez hatanın varyansıdır. 

---

# Kestirim modelinin tahmini 

- `\(n\)` gözlemden oluşan bir eğitim (training) veri setimiz olsun. 

- Öznitelikler: `\(\mathbf{X}_i = \{X_{i1}, X_{i2},\ldots, X_{ip}\}\)`, `\(i=1,2,\ldots,n\)`
- Çıktı değerleri: `\(Y_1, Y_2, \ldots, Y_n\)` 
- Amaç eğitim verilerinden hareketle `\(f(X)\)` kestirim modelinin (kara kutu?) tahmini. 
- Kullanabileceğimiz istatistiksel öğrenme yöntemleri iki ana gruba ayrılabilir: 
  - **Parametrik Yöntemler**: modelin formuna ilişkin bir varsayım gerektirir (doğrusal, karesel, kübik, vb)
  - **Parametrik olmayan yöntemler**: `\(f\)`'in fonksiyonel kalıbına ilişkin bir varsayım yapılmaz. Kestirimlerin gözlemlenen değerlere mümkün olduğunca yaklaştırılması amaçlanır

---
# Parametrik Yöntemler 

Kabaca iki adımdan oluşur: 

1.ADIM:  Kestirim fonksiyonu f( )’in şekline ilişkin varsayım yapmamız gerekir, örneğin doğrusal, karesel, kübik, vs. 

Örneğin: Lineer kalıp
`$$f_L(X) = \beta_0 + \beta_1 X+\epsilon$$`
Karesel Kalıp: 
`$$f_Q(X) = \beta_0 + \beta_1 X+ \beta_2 X^2 + \epsilon$$`


2.ADIM:  Eğitim verilerinden hareketle modelin tahmini (eğitimi, uyumu) için bir yöntemin uygulanması. Örneğin, doğrusal regresyon modeli için sıradan en küçük kareler yöntemini kullanabiliriz. 

---
# Örnek: Doğrusal ve Karesel Modeller 

.pull-left[
$$\hat{f}_L(X) = \hat{\beta}_0 + \hat{\beta}_1 X $$
![:scale 90%](img/linfit.png)
]

.pull-right[
`$$\hat{f}_Q(X) = \hat{\beta}_0 + \hat{\beta}_1 X + \hat{\beta}_2 X^2$$`
![:scale 90%](img/qfit.png)
]

Doğrusal kestirim (solda) aşağı yukarı kabul edilebilir bir yaklaştırım sunsa da karesel model daha başarılı görünmektedir.

---
# Örnek: Doğrusal Regresyon Tahmini 
$$\hat{f}_L(eğitim, yaş) = \hat{\beta}_0 + \hat{\beta}_1 eğitim + \hat{\beta}_2 yaş $$

.pull-left[
Kestirim:
![:scale 100%](img/linfit3d.PNG) 
]


.pull-right[
Gerçek ilişki:
![:scale 100%](img/model2.PNG)
]

---
# Parametrik Olmayan Modeller 
Avantaj: esneklik ve kesinlik düzeyi yüksek tahmin

.pull-left[
Kestirim:
![:scale 100%](img/nonpar1.PNG) 
]


.pull-right[
Gerçek ilişki:
![:scale 100%](img/model2.PNG)
]

Tehlike: Fazla uyum (over-fitting)


---
# Over-fitting (Aşırı uyum)
.pull-left[
Kestirim:
![:scale 100%](img/overfit1.PNG) 
]


.pull-right[
Gerçek ilişki:
![:scale 100%](img/model2.PNG)
]

Düzgünleştirme parametresini azaltarak mükemmel uyum sağladık. Ama 
bu kestirimlerin başarılı olacağını garanti etmez. Aslında 
verilerdeki gürültüyü (noise) de modelledik. 

---
# Aşırı uyum: iki boyutlu örnek
Bu grafikte, sırasıyla, lineer model, 4ncü derece polinom, ve 15nci derece polinom tahminleri gösteriliyor. Aşırı uyumun en önemli göstergesi tahminlerin hızlı hareket ederek zikzaklar çizmesidir. 

![:scale 120%](img/overfit2.png)

---

# Aşırı Uyum

.center[![:scale 80%](img/overfitexplain.png)]

&lt;!-- --- --&gt;
&lt;!-- background-image: url("img/overfitexplain.png") --&gt;
&lt;!-- background-size: cover  --&gt;
&lt;!-- background-position: top  --&gt;

---
# Doğruluk vs. Yorumlanabilirlik

- Kısıtlayıcı bir model yerine neden daha esnek bir tahmin modeli kullanmıyoruz? 
- Bunun başlıca iki nedeni vardır: 
1. Doğrusal regresyon gibi kısıtlayıcı varsayımlara dayanan modellerde yorumlama ve istatistiksel çıkarsama çok daha kolaydır. Örneğin, regresyon modelinde `\(\beta_j\)` katsayıları 
`\(X_j\)`'nin çıktı üzerindeki marjinal etkisini ölçer. 
1. Modelin yorumlanabilirliği ikinci planda olsa bile, fonksiyon kalıbı esnek olmayan modeller daha yüksek öndeyi (kestirim, prediction) başarısına sahip olabilirler. 

---
# Esneklik ve Yorumlanabilirlik arasındaki ödünüm

.center[![:scale 70%](img/fig2-7.png)]

(Kaynak: James et al., An Introduction to Statistical Learning, Figure 2.7, s. 25)

---

# Modelin Doğruluğu Nasıl Ölçülür 

- Tahmin doğruluğu (accuracy) tipik olarak Ortalama Hata Karesi (Mean Squared Error - MSE) ile ölçülür

- Modelin `\(y = f(x) + \epsilon\)` olduğunu, tahminin ise `\(\hat{f}(x)\)` ile gösterildiğini varsayalım. 

- Böyle bir regresyon problemi için Ortalama Hata Karesi (MSE) aşağıdaki gibi tanımlanabilir: 
`$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$`
- Burada `\(n\)` gözlemden oluşan bir **eğitim** (training) veri seti kullanılmıştır. 

---

# MSE iyi bir ölçüt mü? 

- Tipik olarak bir gözetimli öğrenme probleminde eğitim verisinde MSE en küçük olacak şekilde tahmin yapılır. Örnek: Sıradan En Küçük Kareler tahmininde kalıntı kareleri toplamını minimum yapan katsayı tahminleri bulunur. 

- Bir makine öğrenmesi uygulamasında asıl amaç eğitim verisinde modelin performansının ne olduğu değildir. Önemli olan tahminde (eğitimde) kullanılmamış yeni bir veri setinde nasıl performans gösterdiğidir. 

- Eğitimde kullanılmayan, sadece kestirim performansının (doğruluğunun) değerlendirilmesinde kullanılan veri setine **test** verileri denir. 

- Eğitim MSE'nin en küçük olması test MSE'nin de en küçük olacağı anlamına gelmez. 

---

# Test MSE 

- Modelin esnekliği arttıkça MSE(eğitim) azalır. 

- Eğitim Verileri: `\(\{Y_i, \mathbf{X}_i\}_{i=1}^n\)`

- Test Verileri: `\(\{Y_{0i}, \mathbf{X}_{0i}\}_{i=1}^m\)`

- Test MSE: 

`$$MSE_{test} = \frac{1}{m}\sum_{i=1}^{m}(y_{0i} - \hat{f}(x_{0i}))^2$$`

- Modelin eğitim verilerinden hareketle tahmininden sonra test verileri ile tahmin yapılarak 
kolayca hesaplanabilir. 

- Test verileri nereden geliyor? 

---
class: center, middle 

# Eğitim ve Test MSE Karşılaştırması 

![:scale 82%](img/MSE1.PNG)

Siyah eğri: gerçek ilişki, Tahmin edilen modeller: doğrusal model (kavuniçi), smoothing spline (mavi), daha esnek smoothing spline (yeşil)
(Kaynak: James et al., Figure 2.9, s.31)


---

# Sapma-Varyans Ödünümü 

- Test verilerindeki beklenen Ortalama Hate Karesi aşağıdaki gibi yazılabilir: 
`$$E(MSE_{test})=E\left(y_{0}-\hat{f}\left(x_{0}\right)\right)^{2}=\operatorname{Var}\left(\hat{f}\left(x_{0}\right)\right)+\left[\operatorname{Bias}\left(\hat{f}\left(x_{0}\right)\right)\right]^{2}+\operatorname{Var}(\epsilon)$$`

- Bias = Sapma (yanlılık)

- Beklenen test hatasının azaltılabilmesi için eşanlı olarak hem düşük varyanslı hem de düşük sapmalı öğrenme yönteminin seçilmesi gerekir. 

- Modelin esnekliği (karmaşıklığı) arttıkça varyans artar sapma azalır.


---

# Beklenen MSE(test)

Test MSE (kırmızı) = Modelin varyansı (kavuniçi) + Sapma Kare (mavi) + İndirgenemez Hata Varyansı (yatay kesikli çizgi)


.center[![:scale 75%](img/MSE2.PNG)]

Dikey kesikli çizgi: en küçük test MSE değerini veren karmaşıklık düzeyi (serbestlik derecesi - degrees of freedom) (Kaynak: James et al., Figure 2.12, s.36)


---


# Sınıflandırma Problemleri 

- Çıktı değişkeni: kategorik (ikili ya da çoklu olabilir)

- Yaptığımız tanımlamalar sınıflandırma problemleri için de geçerli. Ancak bazı ufak değişiklikler yapmak gerekebilir. 

- Örneğin, modelin kestirim başarısını değerlendirmede MSE yerine hata oranını kullanacağız. 

- Eğitim verilerindeki hata oranı **yanlış** sınıflandırılan gözlemlerin toplamdaki payıdır: 
`$$\frac{1}{n} \sum_{i=1}^{n} I\left(y_{i} \neq \hat{y}_{i}\right)$$`
Burada `\(I\left(\cdot\right)\)` `\(y_{i} \neq \hat{y}_{i}\)` ise 1, aksi durumda 0 değerini alan bir ikili değişkendir (indicator function). 

- Aynı formülden hareketle `\((y_0, x_0)\)` gibi bir test verisinden hareketle test hata oranı hesaplanabilir. 

---

# Bayes Sınıflandırıcısı 

- Test hata oranını nasıl en düşük yapabiliriz? 

- Bayes Sınıflandırıcısı (classifier): gözlemleri olasılığı en yüksek olan gruba sınıflandır. 

- Bu herhangi bir `\(x_0\)` test verisi için koşullu olasılığın
`$$\operatorname{Pr}\left(Y=j \mid X=x_{0}\right)$$`
en yüksek olduğu sınıfa atamanın yapılacağı anlamına gelir. 

- Örneğin, ikili bir sınıflandırma probleminde (grup 1, grup 2), `\(\operatorname{Pr}\left(Y=1 \mid X=x_{0}\right)&gt;0.5\)` ise grup 1, değilse grup 2'ye sınıflandırma yapılır.

---

# Bayes sınırı


.pull-left[
![:scale 100%](img/class1.PNG)
]

.pull-right[
- mor kesikli çizgi: Bayes sınıflandırma sınırı
- Olasılık 0.5'den büyükse kavuniçi gruba, değilse mavi gruba atama yapılır. 
]


---


# Bayes Hata Oranı 

- Bayes sınıflandırıcısı olanaklı en düşük hata oranını verir. 

- Bayes Hata Oranı: 

`$$1-E\left(\max _{j} \operatorname{Pr}(Y=j \mid X)\right)$$`

- Bayes hata oranı daha önce gördüğümüz indirgenemez hata gibi düşünülebilir. Koşullu dağılım bilinmediği için Bayes hata oranı da bilinemez.  

---

# KNN Sınıflandırıcısı 

- Pratikte test verilerinde Bayes hata oranından daha düşük hata oranı elde edilemez. 

- Bayes sınıflandırıcısını kullanabilmemiz için her grubun koşullu olasılığını verilerden hareketle tahmin etmemiz gerekir. Böyle bir model bulduktan sonra en yüksek olasılıklı sınıf seçilebilir. 

- Koşullu olasılık dağılımının kestiriminde kullanılabilecek bir yöntem K-en yakın komşu (K-Nearest Neighbor, KNN) yöntemidir. 

- KNN yönteminde `\(x_0\)` test noktasına eğitim verisinde en yakın `\(K\)` nokta belirlenir. Daha sonra bu `\(K\)` nokta içinde en fazla sıklığa sahip olan gruba atama yapılır.  


---

# KNN Örnek 

.center[![:scale 75%](img/KNN1.PNG)]

Notlar: `\(K=3\)` için (bkz. soldaki grafik) x noktasına en yakın değerler içinde en fazla sıklığa sahip olan mavi gruptur. KNN karar sınırı sağ tarafta gösterilmiştir. (Kaynak: James et al., Figure 2.14, s.40)

---

# Aşırı uyum tehlikesi 

- KNN sınıflandırıcısında `\(K\)` parametresi modelin performansını önemli ölçüde etkiler. 

- `\(K\)` arttıkça komşuluk içine giren nokta sayısı artar ve model daha **az esnek** hale gelir. 

- `\(K\)` azaldıkça modelin esnekliği artar. 

- Örnek olarak `\(K=1\)` ve `\(K=100\)` durumlarını ele alalım. 

---

# KNN'de Aşırı uyum

.center[![:scale 88%](img/KNN3.PNG)]

(Kaynak: James et al., Figure 2.16, s.41)

---

# KNN Eğitim ve Test Hata Oranları

.center[![:scale 55%](img/KNN4.PNG)]

Not: Kesikli siyah çizgi Bayes hata oranıdır (veriler simülasyonla üretildiği için biliniyor)  (Kaynak: James et al., Figure 2.17, s.42)


---

# Makine Öğrenmesinde Hata Davranışı


.pull-left[
![:scale 100%](img/funpic.png)
]

.pull-right[
- Model karmaşıklığı arttıkça eğitim verisindeki kestirim hatası azalmaya devam eder. 

- Model karmaşıklığı arttıkça test verisindeki kestirim hatası bir noktaya kadar azalır, daha sonra artmaya başlar. Sapma düşük olsa da varyans çok yüksektir (aşırı uyum)

- Test kestirim hatasının en düşük olduğu model için sapma ve varyans en optimal düzeydedir. 
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
